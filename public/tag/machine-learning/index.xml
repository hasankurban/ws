<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Hasan Kurban, Ph.D.</title>
    <link>https://www.hasankurban.com/tag/machine-learning/</link>
      <atom:link href="https://www.hasankurban.com/tag/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Code with  and  Blogdown
© Hasan Kurban, 2020</copyright><lastBuildDate>Mon, 21 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.hasankurban.com/images/icon_hu20e5e5b4446f9fea2c18d55ef2678e39_24096_512x512_fill_lanczos_center_2.png</url>
      <title>Machine Learning</title>
      <link>https://www.hasankurban.com/tag/machine-learning/</link>
    </image>
    
    <item>
      <title>Atom Type Prediction with Machine Learning</title>
      <link>https://www.hasankurban.com/project/atomtypeprediction/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://www.hasankurban.com/project/atomtypeprediction/</guid>
      <description>&lt;p&gt;Our aim is to determine machine learning  (ML) algorithms that can learn nanoparticles best. The mathematical structural features of the ML algorithm which is most compatible with such data  can help material scientist estimate behavior, structural and electronic properties of nano particles in different temperatures and phases.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Artificial Intelligence Based Hospital Appointment System</title>
      <link>https://www.hasankurban.com/project/healthproject/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://www.hasankurban.com/project/healthproject/</guid>
      <description>&lt;p&gt;The fact that some of the symptoms are related to many medical treatment areas causes patients to have difficulty in making an appointment for treatment.  In this project, we design a data-driven system to find solution to this problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Iterative Machine Learning</title>
      <link>https://www.hasankurban.com/project/kmeans-project/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://www.hasankurban.com/project/kmeans-project/</guid>
      <description>&lt;p&gt;In this work, we have described an optimization approach that can be used over any iterative optimization
algorithms to improve their training run-time complexity. To the best of our knowledge, this is the first work that theoretically shows convergence of iterative algorithms over heap structure–instead of over a cost function. This approach is tested over k-means (KM) and expectation-maximization algorithm (EM-T). The experimental results show dramatic improvements over KM and EM-T training run-time through different kinds of testing: scale, dimension, and separability. Regarding cluster error, the traditional algorithms’ and our
extended algorithms’ performances are similar. For future work, clearly one obvious step is to add seeding to KM* drawing from both k-means++ and kd trees. Additionally,we are interested in the broader question of this approach to iterative converging algorithms. Further, are there better structures than heaps? Lastly, parallelization offers some new challenges, but also opportunities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Random Forest</title>
      <link>https://www.hasankurban.com/project/rf-project/</link>
      <pubDate>Sat, 27 Jun 2015 00:00:00 +0000</pubDate>
      <guid>https://www.hasankurban.com/project/rf-project/</guid>
      <description>&lt;p&gt;Random Forests have been used as effective ensemble models for classification. We present in this paper a new type of Random Forests (RFs) called Red(uced)-RF that adopts a new dynamic data reduction principle and a new voting mechanism called Priority Vote Weighting (PV) which improve accuracy, execution time and AUC values compared to Breiman’s RF. Red-RF also shows that the strength of a random forest can increase without noticeably increasing correlation between the trees. We then compare performance of Red-RF and Breiman’s RF in 8 experiments that involve classification problems with datasets of different sizes. Finally, we conduct two additional experiments that involve considerably larger datasets with one million points in each.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
